{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "382A_TO_cDfi",
        "dRwvEIBFsi3q",
        "cZuDFMmn3Imn",
        "MEnd7Vz53Ks6",
        "VeDTO23A3Mie",
        "1qYQMLKUsg36",
        "fGls40CeskZl",
        "Zmwu-g5vPnEv",
        "02OyttjDwWfb",
        "t5Layur17OPs",
        "K4i9CteD0o8Z",
        "MDxL_nKXZYTX",
        "VWspo80L9h1U",
        "1Gi49W2KBiFB",
        "HktmeYHgXktQ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "382A_TO_cDfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4kjD6ZhZAxJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d54a41-6db7-40e8-8233-4462353d7e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PointNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0TfVbOm70_p",
        "outputId": "953d36e0-7375-4a08-9289-a90e894e985a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PointNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plyfile\n",
        "!pip install einops"
      ],
      "metadata": {
        "id": "zBxhebNUCAo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d082b73b-b205-4c93-d7df-d1bf336966c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting plyfile\n",
            "  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.8/dist-packages (from plyfile) (1.21.6)\n",
            "Installing collected packages: plyfile\n",
            "Successfully installed plyfile-0.7.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from plyfile import PlyData\n",
        "import numpy as np\n",
        "import einops\n",
        "\n",
        "BATCHSIZE = 32\n",
        "NPOINTS = 2500\n",
        "EPOCH = 5\n",
        "WORKERS = 2\n",
        "DATAPATH = \"./data/ModelNet40\"\n",
        "device = torch.device('cuda') if torch.cuda.is_available() is True else torch.device('cpu')"
      ],
      "metadata": {
        "id": "cStXtihgs3xQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert"
      ],
      "metadata": {
        "id": "dRwvEIBFsi3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "from pathlib import Path\n",
        "from plyfile import PlyData\n",
        "from tqdm import tqdm, trange\n",
        "import time\n",
        "import pdb\n",
        "import gc\n",
        "\n",
        "def preprocess_off(in_file):\n",
        "\n",
        "    with open(in_file,\"rt\") as f:\n",
        "        # some OFF files in original dataset had OFF345 345 344 where \n",
        "        # OFF collided with the number. Needs \\n\n",
        "        lines = f.readlines()\n",
        "    if lines[0] != 'OFF\\n':\n",
        "        with open(in_file,\"wt\") as f:\n",
        "            lines[0] = lines[0][0:3] + '\\n' + lines[0][3:]\n",
        "            lines = \"\".join(lines)\n",
        "            f.write(lines)\n",
        "            f.close()\n",
        "    else:\n",
        "        f.close()\n",
        "\n",
        "def offFormat_to_plyFormat(C_file):\n",
        "\n",
        "    with open(C_file,\"rt\") as Cf:\n",
        "        lines = Cf.readlines()\n",
        "    with open(C_file,\"wt\") as Cf:\n",
        "        num_points = lines[1].split()[0]\n",
        "        num_faces = lines[1].split()[1]\n",
        "        lines[0] = 'ply\\n'\n",
        "        lines[1] = 'format ascii 1.0\\n'+\\\n",
        "                    'element vertex %s'%num_points+'\\n'+\\\n",
        "                    'property float x\\n'+\\\n",
        "                    'property float y\\n'+\\\n",
        "                    'property float z\\n'+\\\n",
        "                    'element face %s'%num_faces+'\\n'+\\\n",
        "                    'property list uchar int vertex_index\\n'+\\\n",
        "                    'end_header\\n'\n",
        "        lines = \"\".join(lines)\n",
        "        Cf.write(lines)\n",
        "        Cf.close()\n",
        "\n",
        "\n",
        "def full_off_to_ply(p, l, chunksize, num_cpu=None):\n",
        "\n",
        "    print('searching path', p, 'to convert .off files to .ply')\n",
        "\n",
        "    if (num_cpu != None):\n",
        "        start = time.time()\n",
        "        with Pool(processes = num_cpu) as po0:\n",
        "            for i in po0.imap_unordered(preprocess_off, l, chunksize=chunksize):\n",
        "                pass\n",
        "        with Pool(processes = num_cpu) as po1:\n",
        "            for i in po1.imap_unordered(offFormat_to_plyFormat, l, chunksize=chunksize):\n",
        "                pass\n",
        "        end = time.time()\n",
        "        print(\"Muti core full_off_to_ply use %3f sec!\" %(end - start))\n",
        "\n",
        "    else:\n",
        "        start = time.time()\n",
        "        for f in l:\n",
        "            preprocess_off(f)\n",
        "        for f in l:\n",
        "            offFormat_to_plyFormat(f)\n",
        "        end = time.time()\n",
        "        print(\"Single core full_off_to_ply use %3f sec!\" %(end - start))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_txt():\n",
        "    # Convert test.txt, train.txt, trainval.txt, val.txt data .off to .ply.\n",
        "    txtNames = glob.glob(r\"*.txt\")\n",
        "\n",
        "    for txtName in txtNames:\n",
        "        with open(txtName,\"rt\") as file:\n",
        "            x = file.read()\n",
        "        with open(txtName, \"wt\") as file:\n",
        "            x = x.replace(\".off\",\".ply\")\n",
        "            file.write(x)\n",
        "\n",
        "def suffix(l):\n",
        "    # Convert all .off suffix to .ply.\n",
        "    for i in l:\n",
        "        tmp = i.with_suffix('.ply')\n",
        "        os.rename(i, tmp)\n",
        "\n",
        "\n",
        "def sub_check(f):\n",
        "\n",
        "    plydata = PlyData.read(f)\n",
        "    del plydata\n",
        "    gc.collect()\n",
        "    \n",
        "\n",
        "def check(p, chunksize, num_cpu=None):\n",
        "    # Use PlyData.read(f) check .ply, if ply file broken, sub_check will crush.\n",
        "    ply = list(p.glob('**/*.ply'))\n",
        "    progress = tqdm(total=len(ply))\n",
        "\n",
        "    if (num_cpu != None):\n",
        "        start = time.time()\n",
        "        with Pool(processes = num_cpu) as po:\n",
        "            for i in po.imap_unordered(sub_check, ply, chunksize=chunksize):\n",
        "                progress.update(1)\n",
        "        end = time.time()\n",
        "        print(\"Muti core check use %3f sec!\" %(end - start))\n",
        "    else:\n",
        "        start = time.time()\n",
        "        for f in ply:\n",
        "            sub_check(f)\n",
        "            progress.update(1)\n",
        "        end = time.time()\n",
        "        print(\"Single core check use %3f sec!\" %(end - start))\n",
        "num_cpu = multiprocessing.cpu_count()\n",
        "chunksize = 100\n",
        "currPATH = os.getcwd().replace('\\\\','/')\n",
        "p = Path(currPATH)\n",
        "l = list(p.glob('**/*.off'))\n",
        "if isinstance(num_cpu, int):\n",
        "    print(\"Now use %d Threads!\" %num_cpu)\n",
        "else:\n",
        "    num_cpu = None\n",
        "    print(\"Now use single Thread!\")\n",
        "full_off_to_ply(p, l, chunksize, num_cpu)\n",
        "process_txt()\n",
        "suffix(l)\n",
        "check(p, chunksize, num_cpu)\n",
        "print('ur great!')\n",
        "print('All .off format has converted!')"
      ],
      "metadata": {
        "id": "PeoFDxMhECyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_classification.py --dataset ./data/ModelNet40 --nepoch=1 --dataset_type modelnet40"
      ],
      "metadata": {
        "id": "4zLuSP0hBNur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "cZuDFMmn3Imn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelNetDataset(Dataset):\n",
        "  def __init__(self, dataPath, n_points=2500, mode='train', augmentation=True):\n",
        "    with open('./misc/modelnet_id.txt') as f:\n",
        "      ids = [n.strip().split() for n in f.readlines()]\n",
        "    category_to_id = {}\n",
        "    for cat, i in ids:\n",
        "      category_to_id[cat] = int(i)\n",
        "    with open(os.path.join(dataPath, f'{mode}.txt'), 'r') as f:\n",
        "      fileNames = [n.strip() for n in f.readlines()]\n",
        "    self.files = [(os.path.join(dataPath, n), category_to_id[n.split('/')[0]]) for n in fileNames] # (path, category)\n",
        "    self.n_points = n_points\n",
        "    self.augmentation = augmentation\n",
        "    self.category = len(category_to_id.keys())\n",
        "    self.device = device\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    path, category = self.files[index] # eg. glass_box/train/glass_box_0090.ply\n",
        "    points = self.read_points(path) # ex. (11634, 3)\n",
        "    points = self.sampling(points, self.n_points) # (n_points, 3)\n",
        "    points = self.standardization(points)\n",
        "    if self.augmentation is True:\n",
        "      points = self.augment_points(points)\n",
        "    return torch.from_numpy(points.astype(np.float32)), torch.from_numpy(np.array([category]).astype(np.int64))\n",
        "\n",
        "  def read_points(self, path):\n",
        "    with open(path, 'rb') as f:\n",
        "        plydata = PlyData.read(f)\n",
        "    p_x, p_y, p_z = plydata['vertex']['x'], plydata['vertex']['y'], plydata['vertex']['z']\n",
        "    points = np.vstack((p_x, p_y, p_z)).T # ex. (11634, 3)\n",
        "    return points\n",
        "  \n",
        "  def sampling(self, points, n_points):\n",
        "    choice = np.random.choice(len(points), n_points, replace=True)\n",
        "    return points[choice, :]\n",
        "  \n",
        "  def standardization(self, points):\n",
        "    epsilon = 1e-7\n",
        "    return (points - np.mean(points, axis=0)) / (np.std(points, axis=0) + epsilon)\n",
        "  \n",
        "  def augment_points(self, points):\n",
        "    self.rotation(points[:, [0, 2]])\n",
        "    self.jitter(points)\n",
        "    return points\n",
        "  \n",
        "  def rotation(self, matrix):\n",
        "    theta = np.random.uniform(0, np.pi * 2)\n",
        "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
        "    matrix[:] = matrix.dot(rotation_matrix)\n",
        "  \n",
        "  def jitter(self, points):\n",
        "    points[:] = points + np.random.normal(0, 0.02, points.shape)"
      ],
      "metadata": {
        "id": "4jWaJC_HLAAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ModelNetDataset(DATAPATH, mode='train')\n",
        "dataloader = DataLoader(\n",
        "  dataset,\n",
        "  batch_size=BATCHSIZE,\n",
        "  shuffle=True,\n",
        "  num_workers=WORKERS\n",
        ")"
      ],
      "metadata": {
        "id": "DT0__ZLjjVf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet Model"
      ],
      "metadata": {
        "id": "MEnd7Vz53Ks6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STN(nn.Module):\n",
        "  \"\"\"\n",
        "  Spatial Transformer Network\n",
        "  \"\"\"\n",
        "  def __init__(self, dim):\n",
        "    super(STN, self).__init__()\n",
        "    self.dim = dim\n",
        "    self.conv1 = nn.Conv1d(dim, 64, 1)\n",
        "    self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "    self.conv3 = nn.Conv1d(128, 1024, 1)\n",
        "    self.fc1 = nn.Linear(1024, 512)\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "    self.fc3 = nn.Linear(256, dim*dim)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(64)\n",
        "    self.bn2 = nn.BatchNorm1d(128)\n",
        "    self.bn3 = nn.BatchNorm1d(1024)\n",
        "    self.bn4 = nn.BatchNorm1d(512)\n",
        "    self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "  def forward(self, x): # (batch, dim, n_points)\n",
        "    batch, dim, n_points = x.shape # ex. batch=32, n_points=2500\n",
        "    x = self.relu(self.bn1(self.conv1(x))) # (32, 64, 2500)\n",
        "    x = self.relu(self.bn2(self.conv2(x))) # (32, 128, 2500)\n",
        "    x = self.relu(self.bn3(self.conv3(x))) # (32, 1024, 2500)\n",
        "    x = einops.reduce(x, 'B D N -> B D', 'max') # pointwise pooling (32, 1024)\n",
        "    x = self.relu(self.bn4(self.fc1(x))) # (32, 512)\n",
        "    x = self.relu(self.bn5(self.fc2(x))) # (32, 256)\n",
        "    x = self.fc3(x) # (32, dim*dim)\n",
        "    iden = torch.eye(dim).view(1, -1)\n",
        "    iden = iden.cuda() if x.is_cuda else iden\n",
        "    x = x + iden\n",
        "    x = x.view(-1, dim, dim) # (32, dim, dim)\n",
        "    return x\n",
        "\n",
        "\n",
        "class PointNetFeature(nn.Module):\n",
        "  def __init__(self, in_channel=3, channels=[64, 128, 1024], stn=True): \n",
        "    super(PointNetFeature, self).__init__()\n",
        "    self.stn = stn\n",
        "    if stn is True:\n",
        "      self.stn = STN(in_channel)\n",
        "      self.fstn = STN(channels[0])\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.bns = nn.ModuleList()\n",
        "    last_channel = in_channel\n",
        "    for c in channels:\n",
        "      self.convs.append(nn.Conv1d(last_channel, c, 1))\n",
        "      self.bns.append(nn.BatchNorm1d(c))\n",
        "      last_channel = c\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x): # (batch, C, n_points)\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        x : (B, C, N) if keypoint_wise is False else (B, C, N, S)\n",
        "    Return:\n",
        "        global_feature : (B, D3)\n",
        "        local_feature : (B, D1, N)\n",
        "        last_feature : (B, D3, N)\n",
        "        trans_mat : (B, D1, D1)\n",
        "    \"\"\"\n",
        "    if self.stn is True:\n",
        "      x = einops.einsum(x, self.stn(x), 'B C N, B C C2 -> B C2 N') # (batch, n_points, 3)\n",
        "      x = self.relu(self.bns[0](self.convs[0](x))) # (batch, 64, n_points)\n",
        "      trans_mat = self.fstn(x) # (32, 64, 64)\n",
        "      x = einops.einsum(x, trans_mat, 'B C N, B C C2 -> B C2 N') \n",
        "      local_feature = x\n",
        "      for conv, bn in zip(self.convs[1:], self.bns[1:]):\n",
        "        x = self.relu(self.bn(self.conv(x)))\n",
        "    else:\n",
        "      for i, (conv, bn) in enumerate(zip(self.convs, self.bns)):\n",
        "        x = self.relu(bn(conv(x)))\n",
        "        if i == 0:\n",
        "          local_feature = x\n",
        "      trans_mat = None\n",
        "    last_feature = x\n",
        "    global_feature = einops.reduce(x, 'B C N -> B C', 'max')\n",
        "    return global_feature, local_feature, last_feature, trans_mat # (b, 1024), (b, 64, n), (b, 64, 64), trans_mat is returned together for regularization\n",
        "\n",
        "class PointNetCls(nn.Module):\n",
        "  def __init__(self, category=2):\n",
        "    super(PointNetCls, self).__init__()\n",
        "    self.feat = PointNetFeature()\n",
        "    self.linear1 = nn.Linear(1024, 512)\n",
        "    self.linear2 = nn.Linear(512, 256)\n",
        "    self.linear3 = nn.Linear(256, category)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    self.bn2 = nn.BatchNorm1d(256)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x): # (batch, n_points, 3)\n",
        "    batch, n_points, _ = x.shape\n",
        "    x = einops.rearrange(x, 'B N C -> B C N')\n",
        "    global_feature, local_feature, _, trans_mat = self.feat(x) # (b, 1024), (b, 64, n), (b, 64, 64)\n",
        "    x = self.bn1(self.linear1(global_feature))\n",
        "    x = self.bn2(self.dropout(self.linear2(x)))\n",
        "    x = self.linear3(x)\n",
        "    return x, trans_mat # (b, category), (b, 64, 64)\n",
        "\n",
        "class PointNetSeg(nn.Module):\n",
        "  def __init__(self, category=2):\n",
        "    super(PointNetSeg, self).__init__()\n",
        "    self.feat = PointNetFeature()\n",
        "    self.conv1 = torch.nn.Conv1d(1024+64, 512, 1)\n",
        "    self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
        "    self.conv3 = torch.nn.Conv1d(256, 128, 1)\n",
        "    self.conv4 = torch.nn.Conv1d(128, category, 1)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    self.bn2 = nn.BatchNorm1d(256)\n",
        "    self.bn3 = nn.BatchNorm1d(128)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x): # (batch, n_points, 3)\n",
        "    batch, n_points, _ = x.shape\n",
        "    x = einops.rearrange(x, 'B N C -> B C N')\n",
        "    global_feature, local_feature, _, trans_mat = self.feat(x) # (b, 1024), (b, 64, n), (b, 64, 64)\n",
        "    concat_feature = torch.cat((local_feature, global_feature.unsqueeze(-1).repeat(1, 1, n_points)), dim=1) # (b, 1088, n)\n",
        "    x = self.bn1(self.conv1(concat_feature))\n",
        "    x = self.bn2(self.conv2(x))\n",
        "    x = self.bn3(self.conv3(x))\n",
        "    x = self.conv4(x) # (b, category, n)\n",
        "    return x, trans_mat\n",
        "\n",
        "class OrthogonalRegLoss(nn.Module):\n",
        "  def __init__(self, alpha=1e-4):\n",
        "    super(OrthogonalRegLoss, self).__init__()\n",
        "    self.alpha = alpha\n",
        "  \n",
        "  def forward(self, mat):\n",
        "    batch, dim, _ = mat.shape\n",
        "    iden = torch.eye(dim).unsqueeze(0)\n",
        "    iden = iden.cuda() if mat.is_cuda else iden\n",
        "    return einops.reduce(torch.norm(einops.einsum(mat, mat, 'B i j, B k j -> B i k') - iden, dim=(1,2)), 'B -> ', 'mean') * self.alpha"
      ],
      "metadata": {
        "id": "3YAe9rYmU1G7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet Training"
      ],
      "metadata": {
        "id": "VeDTO23A3Mie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = PointNetCls(category=dataset.category).to(device)\n",
        "classifier.train()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "orthloss = OrthogonalRegLoss(alpha=1e-4)\n",
        "batch_num = len(dataloader)\n",
        "for epoch in range(EPOCH):\n",
        "  losses, accuracy = [], []\n",
        "  for i, (points, category) in enumerate(dataloader):\n",
        "    points, category = points.to(device), category.to(device)\n",
        "    target = category.flatten()\n",
        "    optimizer.zero_grad()\n",
        "    pred, trans_mat = classifier(points)\n",
        "    loss = loss_fn(pred, target) + orthloss(trans_mat) \n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    pred_choice = pred.argmax(dim=1)\n",
        "    correct = (pred_choice == target).sum()\n",
        "    accuracy.append(correct.item() / BATCHSIZE)\n",
        "    if i > 0 and ((i+1) % 50 == 0 or i+1 == batch_num):\n",
        "      print('[Avg Epoch %d: %d/%d] train avg loss: %f accuracy: %f' % (epoch, i+1, batch_num, sum(losses)/len(losses), sum(accuracy)/len(accuracy)))\n",
        "  torch.save(classifier.state_dict(), \"pointnet_modelnet.pt\")"
      ],
      "metadata": {
        "id": "VBa2Zlrlrt-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "1qYQMLKUsg36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Utils:\n",
        "  @staticmethod\n",
        "  def distance(src_points, tgt_points, channel_first=False):\n",
        "    \"\"\"\n",
        "    src_points : (B, N, C)\n",
        "    tgt_points : (B, M, C)\n",
        "    return : (B, N, M)\n",
        "    \"\"\"\n",
        "    if channel_first is True:\n",
        "      src_points = einops.rearrange(src_points, 'B C N -> B N C')\n",
        "      tgt_points = einops.rearrange(tgt_points, 'B C N -> B N C')\n",
        "    B, N, _ = src_points.shape\n",
        "    _, M, _ = tgt_points.shape\n",
        "    return (((src_points.repeat_interleave(M, dim=1) - tgt_points.repeat(1, N, 1)) ** 2).sum(dim=-1)).reshape(B, N, M)\n",
        "\n",
        "  @staticmethod\n",
        "  def points_by_idx(points, idx, channel_first=False):\n",
        "    \"\"\"\n",
        "    points : (B, N, C)\n",
        "    idx : (B, S)\n",
        "    return : (B, S, C)\n",
        "    \"\"\"\n",
        "    if channel_first is True:\n",
        "      dim = list(points.shape) # (B, C, ##)\n",
        "      dim = [dim[0]] + dim[2:] + [dim[1]] # (B, ##, C)\n",
        "      points = points.reshape(dim)\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    new_points = points[batch_indices, idx, :] # (B, ##, C)\n",
        "    if channel_first is True:\n",
        "      dim = list(new_points.shape)\n",
        "      dim = [dim[0]] + [dim[-1]] + dim[1:-1]\n",
        "      new_points = new_points.reshape(dim)\n",
        "    return new_points\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def farthest_point_sampling(points, n_sample, channel_first=False):\n",
        "    \"\"\"\n",
        "    points : (B, N, C)\n",
        "    n_sample : S\n",
        "    return : (B, S, C)\n",
        "    \"\"\"\n",
        "    if channel_first is True:\n",
        "      points = einops.rearrange(points, 'B C N -> B N C')\n",
        "    B, N, _ = points.shape\n",
        "    S = n_sample\n",
        "    device = points.device\n",
        "    batchidx = torch.arange(B).to(device)\n",
        "    farthest_idx = torch.zeros(B, S, dtype=torch.long).to(device) # (B, S)\n",
        "    for i in range(1, S):\n",
        "      dist = ((points.unsqueeze(1).repeat(1, S, 1, 1) - points[batchidx.view(-1, 1).expand(-1, S), farthest_idx].unsqueeze(2).repeat_interleave(N, dim=2))**2).sum(dim=-1)\n",
        "      idx = dist.min(dim=1)[0].argmax(dim=-1)\n",
        "      farthest_idx[batchidx, torch.tensor([i]).repeat(B)] = idx\n",
        "    sampled_points = Utils.points_by_idx(points, farthest_idx)\n",
        "    if channel_first is True:\n",
        "      sampled_points = einops.rearrange(sampled_points, 'B S C -> B C S')\n",
        "    return sampled_points, farthest_idx\n",
        "\n",
        "  @staticmethod\n",
        "  def query_ball(radius, n_sample, points, centroids, channel_first=False):\n",
        "    \"\"\"\n",
        "    n_sample : S\n",
        "    points : (B, N, C)\n",
        "    centroids : (B, M, C)\n",
        "    return : (B, M, S, C)\n",
        "    \"\"\"\n",
        "    if channel_first is True:\n",
        "      points = einops.rearrange(points, 'B C N -> B N C')\n",
        "      centroids = einops.rearrange(centroids, 'B C N -> B N C')\n",
        "    device = points.device\n",
        "    B, N, _ = points.shape\n",
        "    _, M, _ = centroids.shape\n",
        "    point_idx = torch.arange(N).to(device).view(1, 1, N).repeat(B, M, 1) # (B, M, N) : Indices of points of each group \n",
        "    distanceMat = Utils.distance(centroids, points) # (B, M, N)\n",
        "    point_idx[distanceMat > radius ** 2] = N # Set indices of points outside the group to N(invalid)\n",
        "    point_idx, _ = point_idx.sort(dim=-1)\n",
        "    point_idx = point_idx[:, :, :n_sample] # collect N samples (B, M, n_sample)\n",
        "    invalid_mask = point_idx == N\n",
        "    pad_points = einops.repeat(point_idx[:, :, 0], 'B M -> B M repeat', repeat=n_sample) # use first point for each group to pad invalid points(N)\n",
        "    point_idx[invalid_mask] = pad_points[invalid_mask]\n",
        "    if channel_first is True:\n",
        "      return Utils.points_by_idx(points, point_idx.reshape(B, -1)).reshape(B, -1, M, n_sample), point_idx # (B, C, M*S)\n",
        "    else:\n",
        "      return Utils.points_by_idx(points, point_idx.reshape(B, -1)).reshape(B, M, n_sample, -1), point_idx # (B, C, M*S)\n",
        "  \n",
        "  @staticmethod\n",
        "  def sample_and_group(n_keypoint, radius, n_sample, point_xyz, point_features=None, concat=True, channel_first=False):\n",
        "      \"\"\"\n",
        "      * channel dim is set to second dim if channel_first is True (e.g (B, N, 3) -> (B, 3, N))\n",
        "      Input:\n",
        "          point_xyz: input points position data, [B, N, 3]\n",
        "          point_features: input points data, [B, N, C] \n",
        "      Return:\n",
        "          keypoint_xyz : [B, n_keypoint, 3]\n",
        "          keypoint_idx : [B, n_keypoint]\n",
        "          grouped_idx : [B, n_keypoint, n_sample]\n",
        "          grouped_xyz: sampled points position data, [B, n_keypoint, n_sample, 3]\n",
        "          final_features: [B, n_keypoint, n_sample, D] if concat is False else [B, n_keypoint, n_sample, 3+C]\n",
        "      \"\"\"\n",
        "      if channel_first is True:\n",
        "        point_xyz = einops.rearrange(point_xyz, 'B C N -> B N C')\n",
        "        if point_features is not None:\n",
        "          point_features = einops.rearrange(point_features, 'B C N -> B N C')\n",
        "      B, N, C = point_xyz.shape\n",
        "      S = n_keypoint\n",
        "      keypoints_idx = None\n",
        "      keypoint_xyz, keypoints_idx = Utils.farthest_point_sampling(point_xyz, n_keypoint) # [B, n_keypoint, 3]\n",
        "      grouped_xyz, grouped_idx = Utils.query_ball(radius, n_sample, point_xyz, keypoint_xyz) # [B, n_keypoint, n_sample, 3], [B, n_keypoint, n_sample]\n",
        "      grouped_xyz_norm = grouped_xyz - keypoint_xyz.view(B, S, 1, C)\n",
        "      if point_features is None:\n",
        "        final_features = grouped_xyz_norm\n",
        "      else:\n",
        "        grouped_features = Utils.points_by_idx(point_features, grouped_idx.reshape(B, -1)).reshape(B, n_keypoint, n_sample, -1) # [B, npoint, n_sample, D]\n",
        "        if concat is True:\n",
        "          final_features = torch.cat([grouped_xyz_norm, grouped_features], dim=-1)\n",
        "        else:\n",
        "          final_features = grouped_features     \n",
        "      if channel_first is True:\n",
        "        keypoint_xyz = einops.rearrange(keypoint_xyz, 'B N C -> B C N')\n",
        "        grouped_xyz_norm = einops.rearrange(grouped_xyz_norm, 'B N S C -> B C N S')\n",
        "        final_features = einops.rearrange(final_features, 'B N S C -> B C N S')\n",
        "      return keypoint_xyz, keypoints_idx, grouped_idx, grouped_xyz_norm, final_features\n",
        "\n",
        "  @staticmethod\n",
        "  def sample_and_group_all(point_xyz, point_features=None, concat=True, channel_first=False):\n",
        "      \"\"\"\n",
        "      * channel dim is set to second dim if channel_first is True (e.g (B, N, 3) -> (B, 3, N))\n",
        "      Input:\n",
        "          point_xyz: input points position data, [B, N, 3] \n",
        "          point_features: input points data, [B, N, C] \n",
        "      Return:\n",
        "          grouped_xyz: sampled points position data, [B, n_keypoint(1), n_sample(N), 3]\n",
        "          final_features: [B, n_keypoint(1), n_sample(N), C] if concat is False else [B, n_keypoint(1), n_sample(N), 3+C]\n",
        "      \"\"\"\n",
        "      if channel_first is True:\n",
        "        point_xyz = einops.rearrange(point_xyz, 'B C N -> B N C')\n",
        "        if point_features is not None:\n",
        "          point_features = einops.rearrange(point_features, 'B C N -> B N C')\n",
        "      B, N, C = point_xyz.shape\n",
        "      grouped_xyz = point_xyz.unsqueeze(1)\n",
        "      if point_features is None:\n",
        "        final_features = grouped_xyz\n",
        "      else:\n",
        "        grouped_features = point_features.unsqueeze(1)\n",
        "        if concat is True:\n",
        "          final_features = torch.cat([grouped_xyz, grouped_features], dim=-1)\n",
        "        else:\n",
        "          final_features = grouped_xyz\n",
        "      if channel_first is True:\n",
        "        grouped_xyz = einops.rearrange(grouped_xyz, 'B N S C -> B C N S')\n",
        "        final_features = einops.rearrange(final_features, 'B N S C -> B C N S')\n",
        "        return None, None, None, grouped_xyz, final_features"
      ],
      "metadata": {
        "id": "HqBgpMXkHGxq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Abstraction & Propagation"
      ],
      "metadata": {
        "id": "fGls40CeskZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SetAbstraction(nn.Module):\n",
        "    def __init__(self, n_keypoint, radius, n_sample, in_channel, channels, group_all, no_feature=False):\n",
        "        super(SetAbstraction, self).__init__()\n",
        "        self.n_keypoint = n_keypoint\n",
        "        self.radius = radius\n",
        "        self.n_sample = n_sample\n",
        "        self.in_channel = in_channel\n",
        "        self.channels = channels\n",
        "        self.group_all = group_all\n",
        "        self.concat = no_feature is False\n",
        "        self.relu = nn.ReLU()\n",
        "        if no_feature is False:\n",
        "          xyz_dim = 3\n",
        "          self.feat = PointNetFeature(in_channel=in_channel+xyz_dim, channels=channels)\n",
        "        else:\n",
        "          self.feat = PointNetFeature(in_channel=in_channel, channels=channels)\n",
        "      \n",
        "    def forward(self, point_xyz, point_features):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            N' : Number of points\n",
        "            point_xyz: input points position data, [B, C, N']\n",
        "            point_features: input points data, [B, D, N']\n",
        "        Return:\n",
        "            N : Number of keypoints\n",
        "            keypoint_xyz: keypoints position data, [B, C, N']\n",
        "            keypoint_features: keypoints feature data, [B, D', N']\n",
        "        \"\"\"\n",
        "        if self.group_all is True:\n",
        "            # None,               [B, 3+D, n_keypoint(1), n_sample(N)]\n",
        "            keypoint_xyz, keypoint_idx, _, _, grouped_features = Utils.sample_and_group_all(point_xyz, point_features=point_features, concat=self.concat, channel_first=True)\n",
        "        else:\n",
        "            # [B, 3, n_keypoint], [B, 3+D, n_keypoint, n_sample]\n",
        "            keypoint_xyz, keypoint_idx, _, _, grouped_features = Utils.sample_and_group(self.n_keypoint, self.radius, self.n_sample, point_xyz, point_features=point_features, concat=self.concat, channel_first=True)\n",
        "        B, D, N, S = grouped_features.shape\n",
        "        grouped_features = einops.rearrange(grouped_features, \"B D N S -> B D (N S)\")\n",
        "        _, _, grouped_features, _ = self.feat(grouped_features)\n",
        "        grouped_features = einops.rearrange(grouped_features, \"B D (N S) -> B D N S\", N=N, S=S)\n",
        "        keypoint_features = einops.reduce(grouped_features, \"B D N S -> B D N\", 'max')\n",
        "        return keypoint_xyz, keypoint_idx, keypoint_features\n",
        "\n",
        "class SetMSGAbstraction(nn.Module):\n",
        "    def __init__(self, n_keypoint, radius_list, n_sample_list, in_channel, channels_list, no_feature=False):\n",
        "      super(SetMSGAbstraction, self).__init__()\n",
        "      self.n_keypoint = n_keypoint\n",
        "      self.radius_list = radius_list\n",
        "      self.n_sample_list = n_sample_list\n",
        "      self.in_channel = in_channel\n",
        "      self.channels_list = channels_list\n",
        "      self.sa_list = nn.ModuleList()\n",
        "      self.concat = no_feature is False\n",
        "      for radius, n_sample, channels in zip(radius_list, n_sample_list, channels_list):\n",
        "        self.sa_list.append(SetAbstraction(n_keypoint, radius, n_sample, in_channel, channels, False, no_feature=no_feature))\n",
        "\n",
        "    def forward(self, point_xyz, point_features):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            N' : Number of points\n",
        "            point_xyz: input points position data, [B, C, N']\n",
        "            point_features: input points data, [B, D, N']\n",
        "        Return:\n",
        "            N : Number of keypoints\n",
        "            M : Number of scales\n",
        "            keypoint_xyz: keypoints position data, [B, C, N']\n",
        "            keypoint_features: keypoints feature data, [B, M*D', N']\n",
        "        \"\"\"\n",
        "        feature_list = []\n",
        "        for i, sa in enumerate(self.sa_list):\n",
        "          keypoint_xyz, keypoint_idx, keypoint_feature = sa(point_xyz, point_features)\n",
        "          feature_list.append(keypoint_feature)\n",
        "        return keypoint_xyz, keypoint_idx, torch.cat(feature_list, dim=1)\n",
        "\n",
        "class FeaturePropagation(nn.Module):\n",
        "    def __init__(self, in_channel, mlp):\n",
        "        super(FeaturePropagation, self).__init__()\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
        "            last_channel = out_channel\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, xyz1, xyz2, features1, features2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            xyz1: input points position data, [B, C, N]\n",
        "            xyz2: sampled input points position data, [B, C, S]\n",
        "            features1: input points data, [B, D1, N]\n",
        "            features2: input points data, [B, D2, S]\n",
        "        Return:\n",
        "            upsampled_points: upsampled points data, [B, D, N]\n",
        "        \"\"\"\n",
        "        B, C, N = xyz1.shape\n",
        "\n",
        "        if xyz2 is None or xyz2.shape[-1] == 1:\n",
        "            interpolated_points = features2.repeat(1, 1, N)\n",
        "        else:\n",
        "            dists = Utils.distance(xyz1, xyz2, channel_first=True) # [B, N, S]\n",
        "            dists, idx = dists.sort(dim=-1)\n",
        "            dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
        "            dist_recip = 1.0 / (dists + 1e-8)\n",
        "            norm = einops.reduce(dist_recip, 'B N T -> B N 1', 'sum')\n",
        "            weight = einops.rearrange(dist_recip / norm, 'B N T -> B 1 N T') # T : 3\n",
        "            sampled_points = Utils.points_by_idx(features2, idx, channel_first=True) # [B, D, N, T]\n",
        "            interpolated_points = einops.reduce(sampled_points * weight, 'B D N T -> B D N', 'sum')\n",
        "        if features1 is not None:\n",
        "            upsampled_points = torch.cat([features1, interpolated_points], dim=1)\n",
        "        else:\n",
        "            upsampled_points = interpolated_points\n",
        "        for i, (bn, conv) in enumerate(zip(self.mlp_bns, self.mlp_convs)):\n",
        "            upsampled_points = self.relu(bn(conv(upsampled_points)))\n",
        "        return upsampled_points"
      ],
      "metadata": {
        "id": "nlNIQXmjsdCw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++(Classification + SSG)"
      ],
      "metadata": {
        "id": "Zmwu-g5vPnEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2Cls(nn.Module):\n",
        "  def __init__(self, category=2, channel_first=False):\n",
        "    super(PointNet2Cls, self).__init__()\n",
        "    self.sa_layers = nn.ModuleList([\n",
        "        SetAbstraction(512, 0.2, 32, 3, [64, 64, 128], False, no_feature=True),\n",
        "        SetAbstraction(128, 0.4, 32, 128, [128, 128, 256], False),\n",
        "        SetAbstraction(None, None, None, 256, [256, 512, 1024], True)\n",
        "    ])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256, category)\n",
        "    )\n",
        "    self.channel_first = channel_first\n",
        "\n",
        "  def forward(self, xyz): # (batch, n_points, 3)\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, _, _ = xyz.shape\n",
        "    features = None\n",
        "    for sa in self.sa_layers:\n",
        "      xyz, _, features = sa(xyz, features)\n",
        "    x = einops.rearrange(features, 'B C 1 -> B C')\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "xg3PPB7APoT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++(Classification + MSG)"
      ],
      "metadata": {
        "id": "02OyttjDwWfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2ClsMSG(nn.Module):\n",
        "  def __init__(self, category=2, channel_first=False):\n",
        "    super(PointNet2ClsMSG, self).__init__()\n",
        "    self.sa_layers = nn.ModuleList([\n",
        "        SetMSGAbstraction(512, [0.1, 0.2, 0.4], [16, 32, 128], 3, [[32, 32, 64], [64, 64, 128], [64, 96, 128]], no_feature=True),\n",
        "        SetMSGAbstraction(128, [0.2, 0.4, 0.8], [32, 64, 128], 64+128+128,[[64, 64, 128], [128, 128, 256], [128, 128, 256]]),\n",
        "        SetAbstraction(None, None, None, 128+256+256, [256, 512, 1024], True)\n",
        "    ])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(1024, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256, category)\n",
        "    )\n",
        "    self.channel_first = channel_first\n",
        "\n",
        "  def forward(self, xyz): # (batch, n_points, 3)\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, _, _ = xyz.shape\n",
        "    features = None\n",
        "    for sa in self.sa_layers:\n",
        "      xyz, _, features = sa(xyz, features)\n",
        "    x = einops.rearrange(features, 'B C 1 -> B C')\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "gx-ujTb-wWiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++(Classification + MRG)"
      ],
      "metadata": {
        "id": "t5Layur17OPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2ClsMRG(nn.Module):\n",
        "  def __init__(self, category=2, channel_first=False):\n",
        "    super(PointNet2ClsMRG, self).__init__()\n",
        "    self.branch1 = nn.ModuleList([\n",
        "        SetAbstraction(512, 0.2, 32, 3, [64, 64, 128], False, no_feature=True),\n",
        "        SetAbstraction(64, 0.4, 32, 128, [128, 128, 256], False)\n",
        "    ])\n",
        "    self.branch2 = nn.ModuleList([\n",
        "        SetAbstraction(512, 0.4, 32, 3, [64, 128, 256], False, no_feature=True),\n",
        "    ])\n",
        "    self.branch3 = nn.ModuleList([\n",
        "        SetAbstraction(None, None, None, 3, [64, 128, 256, 512], True, no_feature=True),\n",
        "    ])\n",
        "    self.branch4 = nn.ModuleList([\n",
        "        SetAbstraction(None, None, None, 256+256, [256, 512, 1024], True, no_feature=False),\n",
        "    ])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(1024 + 512, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(256, category)\n",
        "    )\n",
        "    self.channel_first = channel_first\n",
        "\n",
        "  def forward(self, xyz): # (batch, n_points, 3)\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, _, _ = xyz.shape\n",
        "\n",
        "    features1 = None\n",
        "    xyz1 = xyz\n",
        "    for sa in self.branch1:\n",
        "      xyz1, idx1, features1 = sa(xyz1, features1) # (B, 3, 64), (B, 64), (B, C, 64)\n",
        "\n",
        "    features2 = None\n",
        "    xyz2 = xyz\n",
        "    for sa in self.branch2:\n",
        "      xyz2, _, features2 = sa(xyz2, features2) # (B, 3, 512), (B, C, 512)\n",
        "    features2 = einops.rearrange(features2, \"B C N -> B N C\")\n",
        "    _, S = idx1.shape\n",
        "    batchidx = einops.rearrange(torch.arange(B), \"B -> B 1\")\n",
        "    features2 = einops.rearrange(features2[batchidx, idx1], \"B N C -> B C N\") # (B, C, 64)\n",
        "\n",
        "    features3 = None\n",
        "    xyz3 = xyz\n",
        "    for sa in self.branch3:\n",
        "      _, _, features3 = sa(xyz3, features3) # (B, C, 1)\n",
        "\n",
        "    features4 = torch.cat([features1, features2], dim=1)\n",
        "    xyz4 = xyz1\n",
        "    for sa in self.branch4:\n",
        "      _, _, features4 = sa(xyz4, features4) # (B, C, 1)\n",
        "    \n",
        "    final_features = torch.cat([features3, features4], dim=1)\n",
        "\n",
        "    x = einops.rearrange(final_features, 'B C 1 -> B C')\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4p3AiPXK7QtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++ (Part segmentation + SSG)"
      ],
      "metadata": {
        "id": "K4i9CteD0o8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2PartSeg(nn.Module):\n",
        "  def __init__(self, cls_cat=16, cls_seg=50, channel_first=False):\n",
        "    super(PointNet2PartSeg, self).__init__()\n",
        "    self.channel_first = channel_first\n",
        "    self.sa1 = SetAbstraction(512, 0.2, 32, 3, [64, 64, 128], False, no_feature=True)\n",
        "    self.sa2 = SetAbstraction(128, 0.4, 32, 128, [128, 128, 256], False)\n",
        "    self.sa3 = SetAbstraction(None, None, None, 256, [256, 512, 1024], True)\n",
        "    xyz_dim = 3\n",
        "    self.fp1 = FeaturePropagation(1024+256, [256, 256])\n",
        "    self.fp2 = FeaturePropagation(256+128, [256, 128])\n",
        "    self.fp3 = FeaturePropagation(128+cls_cat+xyz_dim, [128, 128, 128])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, 128, 1),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, cls_seg, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, xyz, cls_label): # cls_label is one-hot (B, cls_cat)\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, C, N = xyz.shape\n",
        "    xyz0 = xyz\n",
        "    features0 = None\n",
        "    xyz1, _, features1 = self.sa1(xyz0, features0)\n",
        "    xyz2, _, features2 = self.sa2(xyz1, features1)\n",
        "    xyz3, _, features3 = self.sa3(xyz2, features2)\n",
        "    features2_upsampled = self.fp1(xyz2, xyz3, features2, features3)\n",
        "    features1_upsampled = self.fp2(xyz1, xyz2, features1, features2_upsampled)\n",
        "    cls_label = einops.repeat(cls_label, 'B cat -> B cat N', N=N)\n",
        "    features0_upsampled = self.fp3(xyz0, xyz1, torch.cat([cls_label, xyz0], dim=1), features1_upsampled)\n",
        "    x = self.ffn(features0_upsampled) # (B, C, N)\n",
        "    x = einops.rearrange(x, 'B C N -> B N C')\n",
        "    return x"
      ],
      "metadata": {
        "id": "uRzfrajd063T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++ (Part segmentation + MSG)"
      ],
      "metadata": {
        "id": "MDxL_nKXZYTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2PartSegMSG(nn.Module):\n",
        "  def __init__(self, cls_cat=16, cls_seg=50, channel_first=False):\n",
        "    super(PointNet2PartSegMSG, self).__init__()\n",
        "    self.channel_first = channel_first\n",
        "    self.sa1 = SetMSGAbstraction(512, [0.1, 0.2, 0.4], [16, 32, 128], 3, [[32, 32, 64], [64, 64, 128], [64, 96, 128]], no_feature=True)\n",
        "    self.sa2 = SetMSGAbstraction(128, [0.2, 0.4, 0.8], [32, 64, 128], 64+128+128, [[64, 64, 128], [128, 128, 256], [128, 128, 256]])\n",
        "    self.sa3 = SetAbstraction(None, None, None, 128+256+256, [256, 512, 1024], True)\n",
        "    xyz_dim = 3\n",
        "    self.fp1 = FeaturePropagation((128+256+256)+1024, [256, 256])\n",
        "    self.fp2 = FeaturePropagation((64+128+128)+256, [256, 128])\n",
        "    self.fp3 = FeaturePropagation((cls_cat+xyz_dim)+128, [128, 128, 128])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, 128, 1),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, cls_seg, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, xyz, cls_label): # cls_label is one-hot (B, cls_cat)\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, C, N = xyz.shape\n",
        "    xyz0 = xyz\n",
        "    features0 = None\n",
        "    xyz1, _, features1 = self.sa1(xyz0, features0)\n",
        "    xyz2, _, features2 = self.sa2(xyz1, features1)\n",
        "    xyz3, _, features3 = self.sa3(xyz2, features2)\n",
        "    features2_upsampled = self.fp1(xyz2, xyz3, features2, features3)\n",
        "    features1_upsampled = self.fp2(xyz1, xyz2, features1, features2_upsampled)\n",
        "    cls_label = einops.repeat(cls_label, 'B cat -> B cat N', N=N)\n",
        "    features0_upsampled = self.fp3(xyz0, xyz1, torch.cat([cls_label, xyz0], dim=1), features1_upsampled)\n",
        "    x = self.ffn(features0_upsampled) # (B, C, N)\n",
        "    x = einops.rearrange(x, 'B C N -> B N C')\n",
        "    return x"
      ],
      "metadata": {
        "id": "9dPm3NVCZcW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++ (Semantic Segmentation + SSG)"
      ],
      "metadata": {
        "id": "VWspo80L9h1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2SemSeg(nn.Module):\n",
        "  def __init__(self, cls_seg=50, channel_first=False):\n",
        "    super(PointNet2SemSeg, self).__init__()\n",
        "    self.channel_first = channel_first\n",
        "    self.sa1 = SetAbstraction(1024, 0.1, 32, 3, [32, 32, 64], False, no_feature=True)\n",
        "    self.sa2 = SetAbstraction(256, 0.2, 32, 64, [64, 64, 128], False)\n",
        "    self.sa3 = SetAbstraction(64, 0.4, 32, 128, [128, 128, 256], False)\n",
        "    self.sa4 = SetAbstraction(16, 0.8, 32, 256, [256, 256, 512], False)\n",
        "    xyz_dim = 3\n",
        "    self.fp1 = FeaturePropagation(512+256, [256, 256])\n",
        "    self.fp2 = FeaturePropagation(256+128, [256, 256])\n",
        "    self.fp3 = FeaturePropagation(256+64, [256, 128])\n",
        "    self.fp4 = FeaturePropagation(128, [128, 128, 128])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, 128, 1),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, cls_seg, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, xyz):\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, C, N = xyz.shape\n",
        "    xyz0 = xyz\n",
        "    features0 = None\n",
        "    xyz1, _, features1 = self.sa1(xyz0, features0)\n",
        "    xyz2, _, features2 = self.sa2(xyz1, features1)\n",
        "    xyz3, _, features3 = self.sa3(xyz2, features2)\n",
        "    xyz4, _, features4 = self.sa4(xyz3, features3)\n",
        "    features3_upsampled = self.fp1(xyz3, xyz4, features3, features4)\n",
        "    features2_upsampled = self.fp2(xyz2, xyz3, features2, features3_upsampled)\n",
        "    features1_upsampled = self.fp3(xyz1, xyz2, features1, features2_upsampled)\n",
        "    features0_upsampled = self.fp4(xyz0, xyz1, features0, features1_upsampled)\n",
        "    x = self.ffn(features0_upsampled) # (B, C, N)\n",
        "    x = einops.rearrange(x, 'B C N -> B N C')\n",
        "    return x"
      ],
      "metadata": {
        "id": "uRE5USse9o17"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++ (Semantic Segmentation + MSG)"
      ],
      "metadata": {
        "id": "1Gi49W2KBiFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet2SemSegMSG(nn.Module):\n",
        "  def __init__(self, cls_seg=50, channel_first=False):\n",
        "    super(PointNet2SemSegMSG, self).__init__()\n",
        "    self.channel_first = channel_first\n",
        "    self.sa1 = SetMSGAbstraction(1024, [0.05, 0.1], [16, 32], 3, [[16, 16, 32], [32, 32, 64]], no_feature=True)\n",
        "    self.sa2 = SetMSGAbstraction(256, [0.1, 0.2], [16, 32], 32+64, [[64, 64, 128], [64, 96, 128]])\n",
        "    self.sa3 = SetMSGAbstraction(64, [0.2, 0.4], [16, 32], 128+128, [[128, 196, 256], [128, 196, 256]])\n",
        "    self.sa4 = SetMSGAbstraction(16, [0.4, 0.8], [16, 32], 256+256, [[256, 256, 512], [256, 384, 512]])\n",
        "    xyz_dim = 3\n",
        "    self.fp1 = FeaturePropagation(512+512+256+256, [256, 256])\n",
        "    self.fp2 = FeaturePropagation(128+128+256, [256, 256])\n",
        "    self.fp3 = FeaturePropagation(32+64+256, [256, 128])\n",
        "    self.fp4 = FeaturePropagation(128, [128, 128, 128])\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, 128, 1),\n",
        "        nn.BatchNorm1d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Conv1d(128, cls_seg, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, xyz):\n",
        "    if self.channel_first is False:\n",
        "      xyz = einops.rearrange(xyz, 'B N C -> B C N')\n",
        "    B, C, N = xyz.shape\n",
        "    xyz0 = xyz\n",
        "    features0 = None\n",
        "    xyz1, _, features1 = self.sa1(xyz0, features0)\n",
        "    xyz2, _, features2 = self.sa2(xyz1, features1)\n",
        "    xyz3, _, features3 = self.sa3(xyz2, features2)\n",
        "    xyz4, _, features4 = self.sa4(xyz3, features3)\n",
        "    features3_upsampled = self.fp1(xyz3, xyz4, features3, features4)\n",
        "    features2_upsampled = self.fp2(xyz2, xyz3, features2, features3_upsampled)\n",
        "    features1_upsampled = self.fp3(xyz1, xyz2, features1, features2_upsampled)\n",
        "    features0_upsampled = self.fp4(xyz0, xyz1, features0, features1_upsampled)\n",
        "    x = self.ffn(features0_upsampled) # (B, C, N)\n",
        "    x = einops.rearrange(x, 'B C N -> B N C')\n",
        "    return x"
      ],
      "metadata": {
        "id": "AIyNfVkDG4T_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet++ training"
      ],
      "metadata": {
        "id": "HktmeYHgXktQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_cat = 16\n",
        "cls_seg = 50\n",
        "classifier = PointNet2SemSeg(cls_seg=cls_seg)\n",
        "B = 2\n",
        "N = 1500\n",
        "xyz = torch.rand(B, N, 3)\n",
        "cls_label = torch.rand(B, cls_cat)\n",
        "result = classifier(xyz) # (batch, N, seg_cat)\n",
        "print(result.shape)"
      ],
      "metadata": {
        "id": "fCK7qGbaB1MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_cat = 16\n",
        "cls_seg = 50\n",
        "classifier = PointNet2SemSegMSG(cls_seg=cls_seg)\n",
        "B = 2\n",
        "N = 2500\n",
        "xyz = torch.rand(B, N, 3)\n",
        "cls_label = torch.rand(B, cls_cat)\n",
        "result = classifier(xyz) # (batch, N, seg_cat)\n",
        "print(result.shape)"
      ],
      "metadata": {
        "id": "l_KbSH9TJ4QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = PointNet2Cls(category=dataset.category).to(device)\n",
        "classifier.train()\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "orthloss = OrthogonalRegLoss(alpha=1e-4)\n",
        "batch_num = len(dataloader)\n",
        "for epoch in range(EPOCH):\n",
        "  losses, accuracy = [], []\n",
        "  for i, (points, category) in enumerate(dataloader):\n",
        "    points, category = points.to(device), category.to(device)\n",
        "    target = category.flatten()\n",
        "    optimizer.zero_grad()\n",
        "    pred = classifier(points)\n",
        "    loss = loss_fn(pred, target)\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    pred_choice = pred.argmax(dim=1)\n",
        "    correct = (pred_choice == target).sum()\n",
        "    accuracy.append(correct.item() / BATCHSIZE)\n",
        "    if i > 0 and ((i+1) % 50 == 0 or i+1 == batch_num):\n",
        "      print('[Avg Epoch %d: %d/%d] train avg loss: %f accuracy: %f' % (epoch, i+1, batch_num, sum(losses)/len(losses), sum(accuracy)/len(accuracy)))\n",
        "  torch.save(classifier.state_dict(), \"pointnet_modelnet.pt\")"
      ],
      "metadata": {
        "id": "Xc3HmLWeFor5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}