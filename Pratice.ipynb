{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["dRwvEIBFsi3q"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kjD6ZhZAxJq","executionInfo":{"status":"ok","timestamp":1675079316812,"user_tz":-540,"elapsed":20350,"user":{"displayName":"최민혁","userId":"16583330673468718640"}},"outputId":"55a8aa8f-986d-4c33-bd9c-a6ca9123a3f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WW-FNmRXA9PG","executionInfo":{"status":"ok","timestamp":1675068300428,"user_tz":-540,"elapsed":10,"user":{"displayName":"최민혁","userId":"16583330673468718640"}},"outputId":"0f1fb748-4714-4c2d-e991-3a2f39e987f9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["cd ./pointnet.pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFr991oIBLdV","executionInfo":{"status":"ok","timestamp":1675068300428,"user_tz":-540,"elapsed":8,"user":{"displayName":"최민혁","userId":"16583330673468718640"}},"outputId":"e1abe376-c982-422d-a166-fc2401ac61b0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/pointnet.pytorch\n"]}]},{"cell_type":"code","source":["!pip install plyfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBxhebNUCAo0","executionInfo":{"status":"ok","timestamp":1675068304512,"user_tz":-540,"elapsed":4090,"user":{"displayName":"최민혁","userId":"16583330673468718640"}},"outputId":"af5bc71e-0573-4bd6-9121-bee4b6277ddb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting plyfile\n","  Downloading plyfile-0.7.4-py3-none-any.whl (39 kB)\n","Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.8/dist-packages (from plyfile) (1.21.6)\n","Installing collected packages: plyfile\n","Successfully installed plyfile-0.7.4\n"]}]},{"cell_type":"markdown","source":["# Convert"],"metadata":{"id":"dRwvEIBFsi3q"}},{"cell_type":"code","source":["import os\n","import glob\n","import multiprocessing\n","from multiprocessing import Pool\n","from pathlib import Path\n","from plyfile import PlyData\n","from tqdm import tqdm, trange\n","import time\n","import pdb\n","import gc\n","\n","def preprocess_off(in_file):\n","\n","    with open(in_file,\"rt\") as f:\n","        # some OFF files in original dataset had OFF345 345 344 where \n","        # OFF collided with the number. Needs \\n\n","        lines = f.readlines()\n","    if lines[0] != 'OFF\\n':\n","        with open(in_file,\"wt\") as f:\n","            lines[0] = lines[0][0:3] + '\\n' + lines[0][3:]\n","            lines = \"\".join(lines)\n","            f.write(lines)\n","            f.close()\n","    else:\n","        f.close()\n","\n","def offFormat_to_plyFormat(C_file):\n","\n","    with open(C_file,\"rt\") as Cf:\n","        lines = Cf.readlines()\n","    with open(C_file,\"wt\") as Cf:\n","        num_points = lines[1].split()[0]\n","        num_faces = lines[1].split()[1]\n","        lines[0] = 'ply\\n'\n","        lines[1] = 'format ascii 1.0\\n'+\\\n","                    'element vertex %s'%num_points+'\\n'+\\\n","                    'property float x\\n'+\\\n","                    'property float y\\n'+\\\n","                    'property float z\\n'+\\\n","                    'element face %s'%num_faces+'\\n'+\\\n","                    'property list uchar int vertex_index\\n'+\\\n","                    'end_header\\n'\n","        lines = \"\".join(lines)\n","        Cf.write(lines)\n","        Cf.close()\n","\n","\n","def full_off_to_ply(p, l, chunksize, num_cpu=None):\n","\n","    print('searching path', p, 'to convert .off files to .ply')\n","\n","    if (num_cpu != None):\n","        start = time.time()\n","        with Pool(processes = num_cpu) as po0:\n","            for i in po0.imap_unordered(preprocess_off, l, chunksize=chunksize):\n","                pass\n","        with Pool(processes = num_cpu) as po1:\n","            for i in po1.imap_unordered(offFormat_to_plyFormat, l, chunksize=chunksize):\n","                pass\n","        end = time.time()\n","        print(\"Muti core full_off_to_ply use %3f sec!\" %(end - start))\n","\n","    else:\n","        start = time.time()\n","        for f in l:\n","            preprocess_off(f)\n","        for f in l:\n","            offFormat_to_plyFormat(f)\n","        end = time.time()\n","        print(\"Single core full_off_to_ply use %3f sec!\" %(end - start))\n","\n","\n","\n","\n","def process_txt():\n","    # Convert test.txt, train.txt, trainval.txt, val.txt data .off to .ply.\n","    txtNames = glob.glob(r\"*.txt\")\n","\n","    for txtName in txtNames:\n","        with open(txtName,\"rt\") as file:\n","            x = file.read()\n","        with open(txtName, \"wt\") as file:\n","            x = x.replace(\".off\",\".ply\")\n","            file.write(x)\n","\n","def suffix(l):\n","    # Convert all .off suffix to .ply.\n","    for i in l:\n","        tmp = i.with_suffix('.ply')\n","        os.rename(i, tmp)\n","\n","\n","def sub_check(f):\n","\n","    plydata = PlyData.read(f)\n","    del plydata\n","    gc.collect()\n","    \n","\n","def check(p, chunksize, num_cpu=None):\n","    # Use PlyData.read(f) check .ply, if ply file broken, sub_check will crush.\n","    ply = list(p.glob('**/*.ply'))\n","    progress = tqdm(total=len(ply))\n","\n","    if (num_cpu != None):\n","        start = time.time()\n","        with Pool(processes = num_cpu) as po:\n","            for i in po.imap_unordered(sub_check, ply, chunksize=chunksize):\n","                progress.update(1)\n","        end = time.time()\n","        print(\"Muti core check use %3f sec!\" %(end - start))\n","    else:\n","        start = time.time()\n","        for f in ply:\n","            sub_check(f)\n","            progress.update(1)\n","        end = time.time()\n","        print(\"Single core check use %3f sec!\" %(end - start))\n","num_cpu = multiprocessing.cpu_count()\n","chunksize = 100\n","currPATH = os.getcwd().replace('\\\\','/')\n","p = Path(currPATH)\n","l = list(p.glob('**/*.off'))\n","if isinstance(num_cpu, int):\n","    print(\"Now use %d Threads!\" %num_cpu)\n","else:\n","    num_cpu = None\n","    print(\"Now use single Thread!\")\n","full_off_to_ply(p, l, chunksize, num_cpu)\n","process_txt()\n","suffix(l)\n","check(p, chunksize, num_cpu)\n","print('ur great!')\n","print('All .off format has converted!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeoFDxMhECyC","executionInfo":{"status":"ok","timestamp":1674462380301,"user_tz":-540,"elapsed":10273348,"user":{"displayName":"최민혁","userId":"16583330673468718640"}},"outputId":"cbcf9e37-c45d-45b0-b54a-cbaea63cd5c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now use 2 Threads!\n","searching path /content/drive/MyDrive/pointnet.pytorch to convert .off files to .ply\n","Muti core full_off_to_ply use 3234.549246 sec!\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 12311/12311 [1:56:04<00:00,  1.77it/s]"]},{"output_type":"stream","name":"stdout","text":["Muti core check use 6964.572830 sec!\n","ur great!\n","All .off format has converted!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["!python train_classification.py --dataset ./data/ModelNet40 --nepoch=1 --dataset_type modelnet40"],"metadata":{"id":"4zLuSP0hBNur"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Code"],"metadata":{"id":"MkWjGkBbs2kT"}},{"cell_type":"code","source":["from __future__ import print_function\n","import argparse\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from plyfile import PlyData\n","import numpy as np\n","\n","BATCHSIZE = 32\n","NPOINTS = 2500\n","EPOCH = 5\n","WORKERS = 2\n","DATAPATH = \"./data/ModelNet40\"\n","device = torch.device('cuda') if torch.cuda.is_available() is True else torch.device('cpu')"],"metadata":{"id":"cStXtihgs3xQ","executionInfo":{"status":"ok","timestamp":1675068321263,"user_tz":-540,"elapsed":3,"user":{"displayName":"최민혁","userId":"16583330673468718640"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"cZuDFMmn3Imn"}},{"cell_type":"code","source":["class ModelNetDataset(Dataset):\n","  def __init__(self, dataPath, n_points=2500, mode='train', augmentation=True):\n","    with open('./misc/modelnet_id.txt') as f:\n","      ids = [n.strip().split() for n in f.readlines()]\n","    category_to_id = {}\n","    for cat, i in ids:\n","      category_to_id[cat] = int(i)\n","    with open(os.path.join(dataPath, f'{mode}.txt'), 'r') as f:\n","      fileNames = [n.strip() for n in f.readlines()]\n","    self.files = [(os.path.join(dataPath, n), category_to_id[n.split('/')[0]]) for n in fileNames] # (path, category)\n","    self.n_points = n_points\n","    self.augmentation = augmentation\n","    self.category = len(category_to_id.keys())\n","    self.device = device\n","\n","  def __len__(self):\n","    return len(self.files)\n","\n","  def __getitem__(self, index):\n","    path, category = self.files[index] # eg. glass_box/train/glass_box_0090.ply\n","    points = self.read_points(path) # ex. (11634, 3)\n","    points = self.sampling(points, self.n_points) # (n_points, 3)\n","    points = self.standardization(points)\n","    if self.augmentation is True:\n","      points = self.augment_points(points)\n","    return torch.from_numpy(points.astype(np.float32)), torch.from_numpy(np.array([category]).astype(np.int64))\n","\n","  def read_points(self, path):\n","    with open(path, 'rb') as f:\n","        plydata = PlyData.read(f)\n","    p_x, p_y, p_z = plydata['vertex']['x'], plydata['vertex']['y'], plydata['vertex']['z']\n","    points = np.vstack((p_x, p_y, p_z)).T # ex. (11634, 3)\n","    return points\n","  \n","  def sampling(self, points, n_points):\n","    choice = np.random.choice(len(points), n_points, replace=True)\n","    return points[choice, :]\n","  \n","  def standardization(self, points):\n","    epsilon = 1e-7\n","    return (points - np.mean(points, axis=0)) / (np.std(points, axis=0) + epsilon)\n","  \n","  def augment_points(self, points):\n","    self.rotation(points[:, [0, 2]])\n","    self.jitter(points)\n","    return points\n","  \n","  def rotation(self, matrix):\n","    theta = np.random.uniform(0, np.pi * 2)\n","    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n","    matrix[:] = matrix.dot(rotation_matrix)\n","  \n","  def jitter(self, points):\n","    points[:] = points + np.random.normal(0, 0.02, points.shape)"],"metadata":{"id":"4jWaJC_HLAAe","executionInfo":{"status":"ok","timestamp":1675068324694,"user_tz":-540,"elapsed":262,"user":{"displayName":"최민혁","userId":"16583330673468718640"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"MEnd7Vz53Ks6"}},{"cell_type":"code","source":["class STN(nn.Module):\n","  \"\"\"\n","  Spatial Transformer Network\n","  \"\"\"\n","  def __init__(self, dim):\n","    super(STN, self).__init__()\n","    self.dim = dim\n","    self.conv1 = torch.nn.Conv1d(dim, 64, 1)\n","    self.conv2 = torch.nn.Conv1d(64, 128, 1)\n","    self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n","    self.fc1 = nn.Linear(1024, 512)\n","    self.fc2 = nn.Linear(512, 256)\n","    self.fc3 = nn.Linear(256, dim*dim)\n","    self.relu = nn.ReLU()\n","    self.bn1 = nn.BatchNorm1d(64)\n","    self.bn2 = nn.BatchNorm1d(128)\n","    self.bn3 = nn.BatchNorm1d(1024)\n","    self.bn4 = nn.BatchNorm1d(512)\n","    self.bn5 = nn.BatchNorm1d(256)\n","\n","  def forward(self, x): # (batch, dim, n_points)\n","    batch, dim, n_points = x.shape # ex. batch=32, n_points=2500\n","    x = self.relu(self.bn1(self.conv1(x))) # (32, 64, 2500)\n","    x = self.relu(self.bn2(self.conv2(x))) # (32, 128, 2500)\n","    x = self.relu(self.bn3(self.conv3(x))) # (32, 1024, 2500)\n","    x, _ = torch.max(x, dim=2) # pointwise pooling (32, 1024)\n","    x = self.relu(self.bn4(self.fc1(x))) # (32, 512)\n","    x = self.relu(self.bn5(self.fc2(x))) # (32, 256)\n","    x = self.fc3(x) # (32, dim*dim)\n","    iden = torch.eye(dim).view(1, -1)\n","    iden = iden.cuda() if x.is_cuda else iden\n","    x = x + iden\n","    x = x.view(-1, dim, dim) # (32, dim, dim)\n","    return x\n","\n","\n","class PointNetFeature(nn.Module):\n","  def __init__(self): \n","    super(PointNetFeature, self).__init__()\n","    self.stn = STN(3)\n","    self.fstn = STN(64)\n","    self.conv1 = torch.nn.Conv1d(3, 64, 1)\n","    self.conv2 = torch.nn.Conv1d(64, 128, 1)\n","    self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n","    self.bn1 = nn.BatchNorm1d(64)\n","    self.bn2 = nn.BatchNorm1d(128)\n","    self.bn3 = nn.BatchNorm1d(1024)\n","    self.relu = nn.ReLU()\n","  \n","  def forward(self, x): # (batch, 3, n_points)\n","    x = torch.bmm(x.transpose(1, 2), self.stn(x)) # (batch, n_points, 3)\n","    x = x.transpose(1, 2) # (batch, 3, n_points)\n","    x = self.relu(self.bn1(self.conv1(x))) # (batch, 64, n_points)\n","    trans_mat = self.fstn(x) # (32, 64, 64)\n","    x = x.transpose(1, 2)\n","    x = torch.bmm(x, trans_mat) # (batch, n_points, 64)\n","    x = x.transpose(1, 2) # (batch, 64, n_points)\n","    local_feature = x\n","    x = self.relu(self.bn2(self.conv2(x)))  # (batch, 128, n_points)\n","    x = self.relu(self.bn3(self.conv3(x)))  # (batch, 1024, n_points)\n","    global_feature, _ = torch.max(x, dim=-1)\n","    return global_feature, local_feature, trans_mat # (b, 1024), (b, 64, n), (b, 64, 64), trans_mat is returned together for regularization\n","\n","class PointNet(nn.Module):\n","  def __init__(self, category=2, segmentation=False):\n","    super(PointNet, self).__init__()\n","    self.feat = PointNetFeature()\n","    if segmentation is False:\n","      self.linear1 = nn.Linear(1024, 512) # classification\n","      self.linear2 = nn.Linear(512, 256)\n","      self.linear3 = nn.Linear(256, category) # classification\n","      self.bn1 = nn.BatchNorm1d(512)\n","      self.bn2 = nn.BatchNorm1d(256)\n","      self.dropout = nn.Dropout(p=0.3)\n","    else:\n","      self.conv1 = torch.nn.Conv1d(1024+64, 512, 1)\n","      self.conv2 = torch.nn.Conv1d(512, 256, 1)\n","      self.conv3 = torch.nn.Conv1d(256, 128, 1)\n","      self.conv4 = torch.nn.Conv1d(128, category, 1)\n","      self.bn1 = nn.BatchNorm1d(512)\n","      self.bn2 = nn.BatchNorm1d(256)\n","      self.bn3 = nn.BatchNorm1d(128)\n","    self.relu = nn.ReLU()\n","    self.segmentation = segmentation\n","  \n","  def forward(self, x): # (batch, n_points, 3)\n","    batch, n_points, _ = x.shape\n","    x = x.transpose(1, 2)\n","    global_feature, local_feature, trans_mat = self.feat(x) # (b, 1024), (b, 64, n), (b, 64, 64)\n","    if self.segmentation is False:\n","      x = self.bn1(self.linear1(global_feature))\n","      x = self.bn2(self.dropout(self.linear2(x)))\n","      x = self.linear3(x)\n","      return x, trans_mat # (b, category), (b, 64, 64)\n","    else:\n","      concat_feature = torch.cat((local_feature, global_feature.unsqueeze(-1).repeat(1, 1, n_points)), dim=1) # (b, 1088, n)\n","      x = self.bn1(self.conv1(concat_feature))\n","      x = self.bn2(self.conv2(x))\n","      x = self.bn3(self.conv3(x))\n","      x = self.conv4(x) # (b, category, n)\n","      return x, trans_mat\n","\n","class OrthogonalRegLoss(nn.Module):\n","  def __init__(self, alpha=1e-4):\n","    super(OrthogonalRegLoss, self).__init__()\n","    self.alpha = alpha\n","  \n","  def forward(self, mat):\n","    batch, dim, _ = mat.shape\n","    iden = torch.eye(dim).unsqueeze(0)\n","    iden = iden.cuda() if mat.is_cuda else iden\n","    return torch.mean(torch.norm(torch.bmm(mat, mat.transpose(1, 2)) - iden, dim=(1,2))) * self.alpha"],"metadata":{"id":"3YAe9rYmU1G7","executionInfo":{"status":"ok","timestamp":1675068327026,"user_tz":-540,"elapsed":2,"user":{"displayName":"최민혁","userId":"16583330673468718640"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"VeDTO23A3Mie"}},{"cell_type":"code","source":["dataset = ModelNetDataset(DATAPATH, mode='train')\n","dataloader = DataLoader(\n","  dataset,\n","  batch_size=BATCHSIZE,\n","  shuffle=True,\n","  num_workers=WORKERS\n",")"],"metadata":{"id":"DT0__ZLjjVf1","executionInfo":{"status":"ok","timestamp":1675068586784,"user_tz":-540,"elapsed":237,"user":{"displayName":"최민혁","userId":"16583330673468718640"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["classifier = PointNet(category=dataset.category, segmentation=False).to(device)\n","optimizer = optim.Adam(classifier.parameters(), lr=0.001, betas=(0.9, 0.999))\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n","loss_fn = nn.CrossEntropyLoss()\n","orthloss = OrthogonalRegLoss(alpha=1e-4)\n","batch_num = len(dataloader)\n","for epoch in range(EPOCH):\n","  losses, accuracy = [], []\n","  for i, (points, category) in enumerate(dataloader):\n","    points, category = points.to(device), category.to(device)\n","    target = category.flatten()\n","    optimizer.zero_grad()\n","    classifier = classifier.train()\n","    pred, trans_mat = classifier(points)\n","    loss = loss_fn(pred, target) + orthloss(trans_mat) \n","    loss.backward()\n","    losses.append(loss.item())\n","    optimizer.step()\n","    scheduler.step()\n","    pred_choice = pred.argmax(dim=1)\n","    correct = (pred_choice == target).sum()\n","    accuracy.append(correct.item() / BATCHSIZE)\n","    if i > 0 and ((i+1) % 50 == 0 or i+1 == batch_num):\n","      print('[Avg Epoch %d: %d/%d] train avg loss: %f accuracy: %f' % (epoch, i+1, batch_num, sum(losses)/len(losses), sum(accuracy)/len(accuracy)))\n","  torch.save(classifier.state_dict(), \"modelnet.pt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBa2Zlrlrt-G","outputId":"a006fa0c-b93c-4529-aace-fd03a6bf2f9f"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[Epoch 0: 10/246] train loss: 3.539261 accuracy: 0.062500\n","[Epoch 0: 20/246] train loss: 3.728072 accuracy: 0.062500\n","[Epoch 0: 30/246] train loss: 3.493363 accuracy: 0.125000\n","[Epoch 0: 40/246] train loss: 3.186347 accuracy: 0.281250\n","[Epoch 0: 50/246] train loss: 3.398359 accuracy: 0.156250\n","[Epoch 0: 60/246] train loss: 3.340137 accuracy: 0.125000\n","[Epoch 0: 70/246] train loss: 3.244162 accuracy: 0.156250\n","[Epoch 0: 80/246] train loss: 3.194694 accuracy: 0.093750\n","[Epoch 0: 90/246] train loss: 3.309104 accuracy: 0.156250\n","[Epoch 0: 100/246] train loss: 3.196022 accuracy: 0.218750\n","[Epoch 0: 110/246] train loss: 3.516742 accuracy: 0.062500\n","[Epoch 0: 120/246] train loss: 3.202292 accuracy: 0.093750\n","[Epoch 0: 130/246] train loss: 3.300503 accuracy: 0.218750\n","[Epoch 0: 140/246] train loss: 3.219541 accuracy: 0.281250\n","[Epoch 0: 150/246] train loss: 3.532183 accuracy: 0.093750\n","[Epoch 0: 160/246] train loss: 3.415588 accuracy: 0.156250\n","[Epoch 0: 170/246] train loss: 3.236504 accuracy: 0.187500\n","[Epoch 0: 180/246] train loss: 3.533657 accuracy: 0.125000\n","[Epoch 0: 190/246] train loss: 3.320665 accuracy: 0.187500\n","[Epoch 0: 200/246] train loss: 3.206032 accuracy: 0.187500\n","[Epoch 0: 210/246] train loss: 3.284518 accuracy: 0.187500\n","[Epoch 0: 220/246] train loss: 3.511343 accuracy: 0.125000\n","[Epoch 0: 230/246] train loss: 3.027452 accuracy: 0.281250\n","[Epoch 0: 240/246] train loss: 3.440355 accuracy: 0.125000\n","[Epoch 0: 246/246] train loss: 2.872920 accuracy: 0.250000\n","[Epoch 1: 10/246] train loss: 3.466747 accuracy: 0.125000\n","[Epoch 1: 20/246] train loss: 3.042279 accuracy: 0.250000\n","[Epoch 1: 30/246] train loss: 3.218145 accuracy: 0.250000\n","[Epoch 1: 40/246] train loss: 3.291275 accuracy: 0.125000\n","[Epoch 1: 50/246] train loss: 3.214501 accuracy: 0.156250\n","[Epoch 1: 60/246] train loss: 3.449336 accuracy: 0.156250\n","[Epoch 1: 70/246] train loss: 2.695869 accuracy: 0.187500\n","[Epoch 1: 80/246] train loss: 3.041934 accuracy: 0.250000\n","[Epoch 1: 90/246] train loss: 3.404445 accuracy: 0.187500\n","[Epoch 1: 100/246] train loss: 3.234089 accuracy: 0.281250\n","[Epoch 1: 110/246] train loss: 3.046689 accuracy: 0.218750\n","[Epoch 1: 120/246] train loss: 3.279552 accuracy: 0.093750\n","[Epoch 1: 130/246] train loss: 3.172592 accuracy: 0.156250\n","[Epoch 1: 140/246] train loss: 2.706882 accuracy: 0.312500\n","[Epoch 1: 150/246] train loss: 3.066328 accuracy: 0.187500\n","[Epoch 1: 160/246] train loss: 3.030405 accuracy: 0.218750\n","[Epoch 1: 170/246] train loss: 2.953786 accuracy: 0.218750\n","[Epoch 1: 180/246] train loss: 3.376200 accuracy: 0.156250\n","[Epoch 1: 190/246] train loss: 3.026067 accuracy: 0.156250\n","[Epoch 1: 200/246] train loss: 3.206502 accuracy: 0.187500\n","[Epoch 1: 210/246] train loss: 2.913514 accuracy: 0.281250\n","[Epoch 1: 220/246] train loss: 3.212019 accuracy: 0.218750\n","[Epoch 1: 230/246] train loss: 3.504199 accuracy: 0.125000\n","[Epoch 1: 240/246] train loss: 3.034714 accuracy: 0.187500\n","[Epoch 1: 246/246] train loss: 3.323206 accuracy: 0.093750\n"]}]}]}